{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fico-aditama/fad_001_data_mining_fake_news/blob/main/detect_fake_news_with_snorkel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohlfc9MuUt2Z"
      },
      "source": [
        "# Deteksi Berita Palsu Bidang Kesehatan dengan Snorkel dan Perceptron\n",
        "\n",
        "Proyek ini menggunakan pendekatan **Rule-Based Labeling** dengan **Snorkel** untuk memberi label data berita kesehatan secara otomatis, kemudian melatih model **Perceptron** untuk mendeteksi berita palsu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vyZ7DmvUt2f"
      },
      "source": [
        "## 1. Instalasi Library yang Diperlukan\n",
        "Jalankan perintah berikut di terminal atau cell ini untuk menginstal library yang dibutuhkan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dINKuGTZUt2g",
        "outputId": "a844cb2c-2ea0-4a0c-8255-cb21505f46a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: snorkel in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: munkres>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from snorkel) (1.1.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from snorkel) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from snorkel) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from snorkel) (2.5.1+cu124)\n",
            "Requirement already satisfied: tensorboard>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from snorkel) (2.18.0)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from snorkel) (4.25.6)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from snorkel) (3.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (24.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (75.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->snorkel) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.13.0->snorkel) (3.0.2)\n",
            "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, pandas\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.3 which is incompatible.\n",
            "langchain 0.3.19 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 2.2.3 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.3 which is incompatible.\n",
            "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.3 pandas-2.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install snorkel pandas scikit-learn numpy nltk --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cvvm813Ut2i"
      },
      "source": [
        "## 2. Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6abHdUVPUt2j",
        "outputId": "228d4eac-4221-4fc9-f107-4bfc2a308881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from snorkel.labeling import labeling_function, PandasLFApplier\n",
        "from snorkel.labeling.model import LabelModel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE4IrDUaUt2k"
      },
      "source": [
        "## 3. Memuat dan Preprocessing Data\n",
        "Data yang diberikan adalah daftar judul berita dari Kompas.com. Kita akan memuatnya ke dalam DataFrame dan melakukan preprocessing sederhana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL5NQACbUt2l",
        "outputId": "f816bc24-ca3d-4d9c-8645-d304c00e3d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data setelah preprocessing:\n",
            "   No                                       Judul Berita\n",
            "0   1  tragedi penghapusan mandatory spending uu kese...\n",
            "1   2                pindah faskes bpjs kesehatan online\n",
            "2   3  uu kesehatan terbaru str dokter perawat berlak...\n",
            "3   4   uu kesehatan hapus anggaran wajib minimal bidang\n",
            "4   5  uu kesehatan bolehkan dokter asing berpraktik ...\n"
          ]
        }
      ],
      "source": [
        "# Konstanta Label\n",
        "ABSTAIN = -1\n",
        "FAKE = 0\n",
        "TRUE = 1\n",
        "\n",
        "# Buat DataFrame\n",
        "df = pd.DataFrame(pd.read_csv('https://docs.google.com/spreadsheets/d/11TJNGsOvSxns-Vu2dLtylK_7D6e_5zrl/export?format=csv', on_bad_lines='skip'))\n",
        "\n",
        "# Preprocessing teks\n",
        "stop_words = set(stopwords.words('indonesian'))\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Huruf kecil\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Hapus tanda baca dan angka\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Hapus stop words\n",
        "    return text\n",
        "\n",
        "df['Judul Berita'] = df['Judul Berita'].apply(preprocess_text)\n",
        "print(\"Data setelah preprocessing:\")\n",
        "print(df[['No', 'Judul Berita']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XPFRVblUt2m"
      },
      "source": [
        "## 4. Definisi Labeling Functions dengan Snorkel\n",
        "Kita akan membuat aturan sederhana untuk mendeteksi potensi berita palsu berdasarkan kata kunci sensasional atau kontradiksi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eF3kVDHhUt2m"
      },
      "outputs": [],
      "source": [
        "@labeling_function()\n",
        "def sensational_keywords(x):\n",
        "    keywords = ['tragedi', 'ramai', 'kontroversi', 'demo', 'tolak', 'krisis', 'polemik']\n",
        "    return FAKE if any(keyword in x['Judul Berita'] for keyword in keywords) else ABSTAIN\n",
        "\n",
        "@labeling_function()\n",
        "def practical_guide(x):\n",
        "    keywords = ['cara', 'langkah', 'daftar', 'tips', 'panduan']\n",
        "    return TRUE if any(keyword in x['Judul Berita'] for keyword in keywords) else ABSTAIN\n",
        "\n",
        "@labeling_function()\n",
        "def official_source(x):\n",
        "    keywords = ['kemenkes', 'jokowi', 'dpr', 'kpu', 'tni', 'menkes']\n",
        "    return TRUE if any(keyword in x['Judul Berita'] for keyword in keywords) else ABSTAIN\n",
        "\n",
        "@labeling_function()\n",
        "def vague_or_exaggerated(x):\n",
        "    keywords = ['segudang', 'ampuh', 'cepat', 'gratis', 'tanpa']\n",
        "    return FAKE if any(keyword in x['Judul Berita'] for keyword in keywords) else ABSTAIN\n",
        "\n",
        "@labeling_function()\n",
        "def specific_policy(x):\n",
        "    keywords = ['uu', 'ruu', 'perpres', 'aturan', 'pasal']\n",
        "    return TRUE if any(keyword in x['Judul Berita'] for keyword in keywords) else ABSTAIN\n",
        "\n",
        "lfs = [sensational_keywords, practical_guide, official_source, vague_or_exaggerated, specific_policy]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW4uXYPEUt2n"
      },
      "source": [
        "## 5. Menerapkan Labeling Functions dengan Snorkel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb1x90s0Ut2o",
        "outputId": "37eb9ccd-6abc-483f-b934-9856c286b142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 127/127 [00:00<00:00, 2779.69it/s]\n",
            "100%|██████████| 1000/1000 [00:02<00:00, 389.94epoch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hasil Labeling Awal:\n",
            "   No                                       Judul Berita Prediksi\n",
            "0   1  tragedi penghapusan mandatory spending uu kese...     True\n",
            "1   2                pindah faskes bpjs kesehatan online  Abstain\n",
            "2   3  uu kesehatan terbaru str dokter perawat berlak...     True\n",
            "3   4   uu kesehatan hapus anggaran wajib minimal bidang     True\n",
            "4   5  uu kesehatan bolehkan dokter asing berpraktik ...     True\n",
            "5   6  jokowi uu kesehatan direvisi permudah dokter m...     True\n",
            "6   7         ditolak idi ruu kesehatan segudang manfaat     True\n",
            "7   8  uu kesehatan terbaru atur produk tembakau zat ...     True\n",
            "8   9           manfaat ruu kesehatan perlindungan hukum     True\n",
            "9  10  uu kesehatan terbaru abaikan pasien situasi da...     True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df)\n",
        "\n",
        "label_model = LabelModel(cardinality=2, verbose=True)\n",
        "label_model.fit(L_train, n_epochs=1000, log_freq=100, seed=123)\n",
        "\n",
        "df['label'] = label_model.predict(L_train)\n",
        "df['Prediksi'] = df['label'].map({FAKE: 'Fake', TRUE: 'True', ABSTAIN: 'Abstain'})\n",
        "print(\"\\nHasil Labeling Awal:\")\n",
        "print(df[['No', 'Judul Berita', 'Prediksi']].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWWe6B-KUt2o"
      },
      "source": [
        "## 6. Ekstraksi Fitur dan Pelatihan Model Perceptron\n",
        "Kita akan mengubah teks menjadi fitur numerik menggunakan TF-IDF, lalu melatih model Perceptron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mfLG8r0Ut2o",
        "outputId": "6480104d-1ba3-4c7b-a6a1-d025902f55f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.8823529411764706\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.67      0.67      0.67         3\n",
            "        True       0.93      0.93      0.93        14\n",
            "\n",
            "    accuracy                           0.88        17\n",
            "   macro avg       0.80      0.80      0.80        17\n",
            "weighted avg       0.88      0.88      0.88        17\n",
            "\n",
            "\n",
            "Hasil Prediksi Final pada Seluruh Data:\n",
            "      No                                       Judul Berita Prediksi_Final\n",
            "0      1  tragedi penghapusan mandatory spending uu kese...           True\n",
            "1      2                pindah faskes bpjs kesehatan online           Fake\n",
            "2      3  uu kesehatan terbaru str dokter perawat berlak...           True\n",
            "3      4   uu kesehatan hapus anggaran wajib minimal bidang           True\n",
            "4      5  uu kesehatan bolehkan dokter asing berpraktik ...           True\n",
            "..   ...                                                ...            ...\n",
            "122  124   biaya mengurus surat keterangan sehat ditanggung           Fake\n",
            "123  126         anies pemerataan nakes kebijakan kesehatan           True\n",
            "124  127  dokter asing peningkatan kualitas pelayanan ke...           True\n",
            "125  128       kritisi penolak uu kesehatan pakar kesalahan           True\n",
            "126  129  polemik ruu kesehatan didemo ribuan tenaga kes...           True\n",
            "\n",
            "[127 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
        "X = vectorizer.fit_transform(df['Judul Berita']).toarray()\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "mask_train = y_train != ABSTAIN\n",
        "mask_test = y_test != ABSTAIN\n",
        "X_train, y_train = X_train[mask_train], y_train[mask_train]\n",
        "X_test, y_test = X_test[mask_test], y_test[mask_test]\n",
        "\n",
        "perceptron = Perceptron(max_iter=1000, tol=1e-3, random_state=42, eta0=0.1)\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "y_pred = perceptron.predict(X_test)\n",
        "y_test_str = ['Fake' if label == FAKE else 'True' for label in y_test]\n",
        "y_pred_str = ['Fake' if label == FAKE else 'True' for label in y_pred]\n",
        "\n",
        "print('\\nAccuracy:', accuracy_score(y_test, y_pred))\n",
        "print('Classification Report:\\n', classification_report(y_test_str, y_pred_str, target_names=['Fake', 'True']))\n",
        "\n",
        "# Prediksi pada seluruh data\n",
        "df['Prediksi_Final'] = ['Fake' if pred == FAKE else 'True' if pred == TRUE else 'Abstain'\n",
        "                       for pred in perceptron.predict(X)]\n",
        "print(\"\\nHasil Prediksi Final pada Seluruh Data:\")\n",
        "print(df[['No', 'Judul Berita', 'Prediksi_Final']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sra9hdQOUt2o"
      },
      "source": [
        "## 7. Contoh Prediksi pada Data Baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYZ9efGMUt2o",
        "outputId": "45ad300c-6c1b-4644-9312-2e08a587997f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediksi pada Data Baru:\n",
            "Judul: cara cepat sembuh dari flu dengan bpjs kesehatan -> Prediksi: Fake\n",
            "Judul: tragedi besar dokter asing bunuh pasien di ri -> Prediksi: Fake\n",
            "Judul: jokowi umumkan uu kesehatan baru untuk rakyat -> Prediksi: True\n",
            "Judul: ramai dokter palsu banjiri rumah sakit -> Prediksi: True\n"
          ]
        }
      ],
      "source": [
        "new_titles = [\n",
        "    'cara cepat sembuh dari flu dengan bpjs kesehatan',\n",
        "    'tragedi besar dokter asing bunuh pasien di ri',\n",
        "    'jokowi umumkan uu kesehatan baru untuk rakyat',\n",
        "    'ramai dokter palsu banjiri rumah sakit'\n",
        "]\n",
        "new_titles_cleaned = [preprocess_text(title) for title in new_titles]\n",
        "X_new = vectorizer.transform(new_titles_cleaned).toarray()\n",
        "predictions = perceptron.predict(X_new)\n",
        "\n",
        "print(\"\\nPrediksi pada Data Baru:\")\n",
        "for title, pred in zip(new_titles, predictions):\n",
        "    label = 'Fake' if pred == FAKE else 'True'\n",
        "    print(f'Judul: {title} -> Prediksi: {label}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}