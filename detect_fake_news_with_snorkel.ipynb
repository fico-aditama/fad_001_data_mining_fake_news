{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deteksi Berita Palsu Bidang Kesehatan dengan Snorkel dan Perceptron\n",
    "\n",
    "Proyek ini menggunakan pendekatan **Rule-Based Labeling** dengan **Snorkel** untuk memberi label data berita kesehatan secara otomatis, kemudian melatih model **Perceptron** untuk mendeteksi berita palsu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalasi Library yang Diperlukan\n",
    "Jalankan perintah berikut di terminal atau cell ini untuk menginstal library yang dibutuhkan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting snorkel==0.9.0\n",
      "  Using cached snorkel-0.9.0-py3-none-any.whl (131 kB)\n",
      "Requirement already satisfied: pandas in /home/fadi/.local/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in /home/fadi/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in /home/fadi/.local/lib/python3.10/site-packages (1.26.3)\n",
      "Collecting pandas\n",
      "  Downloading pandas-0.24.2.tar.gz (11.8 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m8.6/11.8 MB\u001b[0m \u001b[31m372.0 kB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install snorkel==0.9.0 pandas scikit-learn numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LabelModel' from 'snorkel.labeling' (/home/fadi/.local/lib/python3.10/site-packages/snorkel/labeling/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnorkel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlabeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m labeling_function, PandasLFApplier, LabelModel\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Perceptron\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LabelModel' from 'snorkel.labeling' (/home/fadi/.local/lib/python3.10/site-packages/snorkel/labeling/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from snorkel.labeling import labeling_function, PandasLFApplier, LabelModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memuat dan Preprocessing Data\n",
    "Data yang diberikan adalah daftar judul berita dari Kompas.com. Kita akan memuatnya ke dalam DataFrame dan melakukan preprocessing sederhana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data yang diberikan dalam format tabel\n",
    "data = {\n",
    "    'No': list(range(1, 130)),\n",
    "    'Judul Berita': [\n",
    "        '\"Tragedi Penghapusan \\\"Mandatory Spending\\\" dalam UU Kesehatan ...\"',\n",
    "        'Cara Pindah Faskes BPJS Kesehatan Online',\n",
    "        'UU Kesehatan Terbaru: STR Dokter dan Perawat Berlaku Seumur ...',\n",
    "        # Tambahkan semua judul berita dari dokumen Anda di sini\n",
    "        # Untuk contoh, saya hanya masukkan beberapa\n",
    "        'UU Kesehatan Baru Hapus Anggaran Wajib Minimal di Bidang ...',\n",
    "        'UU Kesehatan Bolehkan Dokter Asing Berpraktik di RI, Kemenkes ...',\n",
    "        # ... dst\n",
    "    ],\n",
    "    'Sumber': ['Kompas.com'] * 129,  # Sesuai jumlah data Anda\n",
    "    'Tanggal': [\n",
    "        '2023-08-13', '2024-07-13', '2023-07-11', '2023-07-12', '2023-07-15',\n",
    "        # Tambahkan tanggal sesuai dokumen Anda\n",
    "    ],\n",
    "    'Kategori': ['Kesehatan'] * 129\n",
    "}\n",
    "\n",
    "# Buat DataFrame (untuk contoh ini, saya hanya masukkan 5 baris pertama)\n",
    "df = pd.DataFrame(data[:5])\n",
    "\n",
    "# Preprocessing: Membersihkan teks\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Ubah ke huruf kecil\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Hapus tanda baca\n",
    "    return text\n",
    "\n",
    "df['Judul Berita'] = df['Judul Berita'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definisi Labeling Functions dengan Snorkel\n",
    "Kita akan membuat aturan sederhana untuk mendeteksi potensi berita palsu berdasarkan kata kunci sensasional atau kontradiksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konstanta untuk label\n",
    "ABSTAIN = -1\n",
    "FAKE = 0\n",
    "REAL = 1\n",
    "\n",
    "# Labeling Function 1: Berita dengan kata sensasional dianggap potensi palsu\n",
    "@labeling_function()\n",
    "def sensational_keywords(x):\n",
    "    keywords = ['tragedi', 'ramai', 'kontroversi', 'demo', 'tolak']\n",
    "    return FAKE if any(keyword in x['Judul Berita'] for keyword in keywords) else ABSTAIN\n",
    "\n",
    "# Labeling Function 2: Berita dengan panduan praktis dianggap asli\n",
    "@labeling_function()\n",
    "def practical_guide(x):\n",
    "    keywords = ['cara', 'langkah', 'daftar', 'tips']\n",
    "    return REAL if any(keyword in x['Judul Berita'] for keyword in keywords) else ABSTAIN\n",
    "\n",
    "# Labeling Function 3: Berita dengan sumber resmi dianggap asli\n",
    "@labeling_function()\n",
    "def official_source(x):\n",
    "    return REAL if 'kemenkes' in x['Judul Berita'] or 'jokowi' in x['Judul Berita'] else ABSTAIN\n",
    "\n",
    "# Daftar semua labeling functions\n",
    "lfs = [sensational_keywords, practical_guide, official_source]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Menerapkan Labeling Functions dengan Snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terapkan labeling functions ke data\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df)\n",
    "\n",
    "# Gunakan LabelModel untuk menggabungkan hasil labeling functions\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=500, log_freq=100, seed=123)\n",
    "\n",
    "# Prediksi label probabilistik\n",
    "df['label'] = label_model.predict(L_train)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ekstraksi Fitur dan Pelatihan Model Perceptron\n",
    "Kita akan mengubah teks menjadi fitur numerik menggunakan TF-IDF, lalu melatih model Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstraksi fitur dengan TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X = vectorizer.fit_transform(df['Judul Berita']).toarray()\n",
    "y = df['label']\n",
    "\n",
    "# Split data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Filter data yang memiliki label valid (bukan ABSTAIN)\n",
    "mask_train = y_train != ABSTAIN\n",
    "mask_test = y_test != ABSTAIN\n",
    "X_train, y_train = X_train[mask_train], y_train[mask_train]\n",
    "X_test, y_test = X_test[mask_test], y_test[mask_test]\n",
    "\n",
    "# Latih model Perceptron\n",
    "perceptron = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi pada data test\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Contoh Prediksi pada Data Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh prediksi pada judul berita baru\n",
    "new_titles = [\n",
    "    'cara cepat sembuh dari flu dengan bpjs kesehatan',\n",
    "    'tragedi besar dokter asing bunuh pasien di ri'\n",
    "]\n",
    "new_titles_cleaned = [preprocess_text(title) for title in new_titles]\n",
    "X_new = vectorizer.transform(new_titles_cleaned).toarray()\n",
    "predictions = perceptron.predict(X_new)\n",
    "\n",
    "for title, pred in zip(new_titles, predictions):\n",
    "    label = 'Palsu' if pred == FAKE else 'Asli'\n",
    "    print(f'Judul: {title} -> Prediksi: {label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
