{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fico-aditama/fad_001_data_mining_fake_news/blob/main/detect_fake_news_with_snorkel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohlfc9MuUt2Z"
      },
      "source": [
        "# Deteksi Berita Palsu Bidang Kesehatan dengan Snorkel dan Perceptron\n",
        "\n",
        "Proyek ini menggunakan pendekatan **Rule-Based Labeling** dengan **Snorkel** untuk memberi label data berita kesehatan secara otomatis, kemudian melatih model **Perceptron** untuk mendeteksi berita palsu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vyZ7DmvUt2f"
      },
      "source": [
        "## 1. Instalasi Library yang Diperlukan\n",
        "Jalankan perintah berikut di terminal atau cell ini untuk menginstal library yang dibutuhkan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dINKuGTZUt2g",
        "outputId": "4d7b63ea-f88d-4c74-ceae-5e18bf1cb2e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snorkel==0.9.0\n",
            "  Downloading snorkel-0.9.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from snorkel==0.9.0) (1.13.1)\n",
            "Collecting pandas\n",
            "  Downloading pandas-0.24.2.tar.gz (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install snorkel==0.9.0 pandas scikit-learn numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cvvm813Ut2i"
      },
      "source": [
        "## 2. Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6abHdUVPUt2j",
        "outputId": "f27a09ac-fd72-45af-ef10-c89e2bd2ff91"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'LabelModel' from 'snorkel.labeling' (/home/fadi/.local/lib/python3.10/site-packages/snorkel/labeling/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnorkel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlabeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m labeling_function, PandasLFApplier, LabelModel\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Perceptron\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'LabelModel' from 'snorkel.labeling' (/home/fadi/.local/lib/python3.10/site-packages/snorkel/labeling/__init__.py)"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from snorkel.labeling import labeling_function, PandasLFApplier, LabelModel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE4IrDUaUt2k"
      },
      "source": [
        "## 3. Memuat dan Preprocessing Data\n",
        "Data yang diberikan adalah daftar judul berita dari Kompas.com. Kita akan memuatnya ke dalam DataFrame dan melakukan preprocessing sederhana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL5NQACbUt2l"
      },
      "outputs": [],
      "source": [
        "# Data yang diberikan dalam format tabel\n",
        "data = {\n",
        "    'No': list(range(1, 130)),\n",
        "    'Judul Berita': [\n",
        "        '\"Tragedi Penghapusan \\\"Mandatory Spending\\\" dalam UU Kesehatan ...\"',\n",
        "        'Cara Pindah Faskes BPJS Kesehatan Online',\n",
        "        'UU Kesehatan Terbaru: STR Dokter dan Perawat Berlaku Seumur ...',\n",
        "        # Tambahkan semua judul berita dari dokumen Anda di sini\n",
        "        # Untuk contoh, saya hanya masukkan beberapa\n",
        "        'UU Kesehatan Baru Hapus Anggaran Wajib Minimal di Bidang ...',\n",
        "        'UU Kesehatan Bolehkan Dokter Asing Berpraktik di RI, Kemenkes ...',\n",
        "        # ... dst\n",
        "    ],\n",
        "    'Sumber': ['Kompas.com'] * 129,  # Sesuai jumlah data Anda\n",
        "    'Tanggal': [\n",
        "        '2023-08-13', '2024-07-13', '2023-07-11', '2023-07-12', '2023-07-15',\n",
        "        # Tambahkan tanggal sesuai dokumen Anda\n",
        "    ],\n",
        "    'Kategori': ['Kesehatan'] * 129\n",
        "}\n",
        "\n",
        "# Buat DataFrame (untuk contoh ini, saya hanya masukkan 5 baris pertama)\n",
        "df = pd.DataFrame(data[:5])\n",
        "\n",
        "# Preprocessing: Membersihkan teks\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Ubah ke huruf kecil\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Hapus tanda baca\n",
        "    return text\n",
        "\n",
        "df['Judul Berita'] = df['Judul Berita'].apply(preprocess_text)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XPFRVblUt2m"
      },
      "source": [
        "## 4. Definisi Labeling Functions dengan Snorkel\n",
        "Kita akan membuat aturan sederhana untuk mendeteksi potensi berita palsu berdasarkan kata kunci sensasional atau kontradiksi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF3kVDHhUt2m"
      },
      "outputs": [],
      "source": [
        "# Konstanta untuk label\n",
        "ABSTAIN = -1\n",
        "FAKE = 0\n",
        "REAL = 1\n",
        "\n",
        "# Labeling Function 1: Berita dengan kata sensasional dianggap potensi palsu\n",
        "@labeling_function()\n",
        "def sensational_keywords(x):\n",
        "    keywords = ['tragedi', 'ramai', 'kontroversi', 'demo', 'tolak']\n",
        "    return FAKE if any(keyword in x['Judul Berita'] for keyword in keywords) else ABSTAIN\n",
        "\n",
        "# Labeling Function 2: Berita dengan panduan praktis dianggap asli\n",
        "@labeling_function()\n",
        "def practical_guide(x):\n",
        "    keywords = ['cara', 'langkah', 'daftar', 'tips']\n",
        "    return REAL if any(keyword in x['Judul Berita'] for keyword in keywords) else ABSTAIN\n",
        "\n",
        "# Labeling Function 3: Berita dengan sumber resmi dianggap asli\n",
        "@labeling_function()\n",
        "def official_source(x):\n",
        "    return REAL if 'kemenkes' in x['Judul Berita'] or 'jokowi' in x['Judul Berita'] else ABSTAIN\n",
        "\n",
        "# Daftar semua labeling functions\n",
        "lfs = [sensational_keywords, practical_guide, official_source]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW4uXYPEUt2n"
      },
      "source": [
        "## 5. Menerapkan Labeling Functions dengan Snorkel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb1x90s0Ut2o"
      },
      "outputs": [],
      "source": [
        "# Terapkan labeling functions ke data\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df)\n",
        "\n",
        "# Gunakan LabelModel untuk menggabungkan hasil labeling functions\n",
        "label_model = LabelModel(cardinality=2, verbose=True)\n",
        "label_model.fit(L_train, n_epochs=500, log_freq=100, seed=123)\n",
        "\n",
        "# Prediksi label probabilistik\n",
        "df['label'] = label_model.predict(L_train)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWWe6B-KUt2o"
      },
      "source": [
        "## 6. Ekstraksi Fitur dan Pelatihan Model Perceptron\n",
        "Kita akan mengubah teks menjadi fitur numerik menggunakan TF-IDF, lalu melatih model Perceptron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mfLG8r0Ut2o"
      },
      "outputs": [],
      "source": [
        "# Ekstraksi fitur dengan TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=500)\n",
        "X = vectorizer.fit_transform(df['Judul Berita']).toarray()\n",
        "y = df['label']\n",
        "\n",
        "# Split data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Filter data yang memiliki label valid (bukan ABSTAIN)\n",
        "mask_train = y_train != ABSTAIN\n",
        "mask_test = y_test != ABSTAIN\n",
        "X_train, y_train = X_train[mask_train], y_train[mask_train]\n",
        "X_test, y_test = X_test[mask_test], y_test[mask_test]\n",
        "\n",
        "# Latih model Perceptron\n",
        "perceptron = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi pada data test\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "# Evaluasi\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('Classification Report:\\n', classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sra9hdQOUt2o"
      },
      "source": [
        "## 7. Contoh Prediksi pada Data Baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYZ9efGMUt2o"
      },
      "outputs": [],
      "source": [
        "# Contoh prediksi pada judul berita baru\n",
        "new_titles = [\n",
        "    'cara cepat sembuh dari flu dengan bpjs kesehatan',\n",
        "    'tragedi besar dokter asing bunuh pasien di ri'\n",
        "]\n",
        "new_titles_cleaned = [preprocess_text(title) for title in new_titles]\n",
        "X_new = vectorizer.transform(new_titles_cleaned).toarray()\n",
        "predictions = perceptron.predict(X_new)\n",
        "\n",
        "for title, pred in zip(new_titles, predictions):\n",
        "    label = 'Palsu' if pred == FAKE else 'Asli'\n",
        "    print(f'Judul: {title} -> Prediksi: {label}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}