{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deteksi Berita Palsu Bidang Kesehatan dengan Snorkel dan Perceptron\n",
    "\n",
    "Proyek ini menggunakan pendekatan **Rule-Based Labeling** dengan **Snorkel** untuk memberi label data berita kesehatan secara otomatis, kemudian melatih model **Perceptron** untuk mendeteksi berita palsu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalasi Library yang Diperlukan\n",
    "Jalankan perintah berikut di terminal atau cell ini untuk menginstal library yang dibutuhkan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snorkel pandas scikit-learn numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from snorkel.labeling import labeling_function, PandasLFApplier, LabelModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memuat dan Preprocessing Data\n",
    "Data yang diberikan adalah daftar judul berita dari Kompas.com. Kita akan memuatnya ke dalam DataFrame dan melakukan preprocessing sederhana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data yang diberikan dalam format tabel\n",
    "data = {\n",
    "    'No': list(range(1, 130)),\n",
    "    'Judul Berita': [\n",
    "        '\"Tragedi Penghapusan \\\"Mandatory Spending\\\" dalam UU Kesehatan ...\"',\n",
    "        'Cara Pindah Faskes BPJS Kesehatan Online',\n",
    "        'UU Kesehatan Terbaru: STR Dokter dan Perawat Berlaku Seumur ...',\n",
    "        # Tambahkan semua judul berita dari dokumen Anda di sini\n",
    "        # Untuk contoh, saya hanya masukkan beberapa\n",
    "        'UU Kesehatan Baru Hapus Anggaran Wajib Minimal di Bidang ...',\n",
    "        'UU Kesehatan Bolehkan Dokter Asing Berpraktik di RI, Kemenkes ...',\n",
    "        # ... dst\n",
    "    ],\n",
    "    'Sumber': ['Kompas.com'] * 129,  # Sesuai jumlah data Anda\n",
    "    'Tanggal': [\n",
    "        '2023-08-13', '2024-07-13', '2023-07-11', '2023-07-12', '2023-07-15',\n",
    "        # Tambahkan tanggal sesuai dokumen Anda\n",
    "    ],\n",
    "    'Kategori': ['Kesehatan'] * 129\n",
    "}\n",
    "\n",
    "# Buat DataFrame (untuk contoh ini, saya hanya masukkan 5 baris pertama)\n",
    "df = pd.DataFrame(data[:5])\n",
    "\n",
    "# Preprocessing: Membersihkan teks\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Ubah ke huruf kecil\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Hapus tanda baca\n",
    "    return text\n",
    "\n",
    "df['Judul Berita'] = df['Judul Berita'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definisi Labeling Functions dengan Snorkel\n",
    "Kita akan membuat aturan sederhana untuk mendeteksi potensi berita palsu berdasarkan kata kunci sensasional atau kontradiksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konstanta untuk label\n",
    "ABSTAIN = -1\n",
    "FAKE = 0\n",
    "REAL = 1\n",
    "\n",
    "# Labeling Function 1: Berita dengan kata sensasional dianggap potensi palsu\n",
    "@labeling_function()\n",
    "def sensational_keywords(x):\n",
    "    keywords = ['tragedi', 'ramai', 'kontroversi', 'demo', 'tolak']\n",
    "    return FAKE if any(keyword in x['Judul Berita'] for keyword in keywords) else ABSTAIN\n",
    "\n",
    "# Labeling Function 2: Berita dengan panduan praktis dianggap asli\n",
    "@labeling_function()\n",
    "def practical_guide(x):\n",
    "    keywords = ['cara', 'langkah', 'daftar', 'tips']\n",
    "    return REAL if any(keyword in x['Judul Berita'] for keyword in keywords) else ABSTAIN\n",
    "\n",
    "# Labeling Function 3: Berita dengan sumber resmi dianggap asli\n",
    "@labeling_function()\n",
    "def official_source(x):\n",
    "    return REAL if 'kemenkes' in x['Judul Berita'] or 'jokowi' in x['Judul Berita'] else ABSTAIN\n",
    "\n",
    "# Daftar semua labeling functions\n",
    "lfs = [sensational_keywords, practical_guide, official_source]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Menerapkan Labeling Functions dengan Snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terapkan labeling functions ke data\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df)\n",
    "\n",
    "# Gunakan LabelModel untuk menggabungkan hasil labeling functions\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=500, log_freq=100, seed=123)\n",
    "\n",
    "# Prediksi label probabilistik\n",
    "df['label'] = label_model.predict(L_train)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ekstraksi Fitur dan Pelatihan Model Perceptron\n",
    "Kita akan mengubah teks menjadi fitur numerik menggunakan TF-IDF, lalu melatih model Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstraksi fitur dengan TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X = vectorizer.fit_transform(df['Judul Berita']).toarray()\n",
    "y = df['label']\n",
    "\n",
    "# Split data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Filter data yang memiliki label valid (bukan ABSTAIN)\n",
    "mask_train = y_train != ABSTAIN\n",
    "mask_test = y_test != ABSTAIN\n",
    "X_train, y_train = X_train[mask_train], y_train[mask_train]\n",
    "X_test, y_test = X_test[mask_test], y_test[mask_test]\n",
    "\n",
    "# Latih model Perceptron\n",
    "perceptron = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi pada data test\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Contoh Prediksi pada Data Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh prediksi pada judul berita baru\n",
    "new_titles = [\n",
    "    'cara cepat sembuh dari flu dengan bpjs kesehatan',\n",
    "    'tragedi besar dokter asing bunuh pasien di ri'\n",
    "]\n",
    "new_titles_cleaned = [preprocess_text(title) for title in new_titles]\n",
    "X_new = vectorizer.transform(new_titles_cleaned).toarray()\n",
    "predictions = perceptron.predict(X_new)\n",
    "\n",
    "for title, pred in zip(new_titles, predictions):\n",
    "    label = 'Palsu' if pred == FAKE else 'Asli'\n",
    "    print(f'Judul: {title} -> Prediksi: {label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
